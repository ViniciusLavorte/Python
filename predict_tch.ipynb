{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O dataset contém dados de 4000 talhões. Um talhão é uma área de cana plantada, como se fosse um \"quarteirão\" de cana com tamanho arbitrário.\n",
    "Os atributos são:\n",
    "* chavesig: identificador do talhao\n",
    "* tch: toneladas de cana por hectare (o que queremos prever)\n",
    "* ndvi_a_p05: indice de vegetação no 5º mês após o plantio\n",
    "* ncorte: número do corte\n",
    "* linhas_falha_km: quantos km de falhas nas linhas de cana do talhao\n",
    "* chuva_dia_pN: média de chuva por dia no mes N antes da colheita\n",
    "* bal_hidrico_pN: balanço hídrico no mes N antes da colheita\n",
    "* espacamento_m: espacamento entre as linhas de cana\n",
    "* area_esti: area estimada do talhaoa\n",
    "\n",
    "Com base nestas informações, construa um modelo capaz de prever, a quantidade de tch que sera colhida com base nos atributos que julgar necessários.\n",
    "É simples, não precisa de nada complicado. Quero ver como vc pensa em fazer isso e como apresenta a linha de raciocínio. O pipeline de trabalho é bem similar ao que tem no script de casas, mas é do zero agora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "base = pd.read_csv('sample_train_dataset_tch_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresentando o cabeçalho dos dados\n",
    "base.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementação: Normalização/Desnormalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tch_y = base['tch']\n",
    "\n",
    "#Normalizando os dados\n",
    "normalized = map(lambda x: (x - tch_y.min())/( tch_y.max()-tch_y.min()), tch_y)\n",
    "normalized = pd.Series(normalized)\n",
    "\n",
    "#Desnormalizando os dados\n",
    "unnormalized = map(lambda y: tch_y.min() + (y*(tch_y.max() - tch_y.min()) ), normalized)\n",
    "unnormalized = pd.Series(unnormalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analisando o número de linhas e colunas\n",
    "base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se há linhas null no dataset\n",
    "base.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#descreve meus dados atraves de metricas\n",
    "base.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lista com as colunas do dataset\n",
    "base.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizando o método Regressão Múltipla\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecionando apenas as colunas necessárias do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas = ['tch','ndvi_a_p05', 'ncorte', 'areaesti','linhas_falha_km', 'chuva_dia_p04', 'chuva_dia_p12',\n",
    "       'bal_hidrico_p12', 'bal_hidrico_p04', 'espacamento_m']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecionando as variáveis independentes X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_x = ['ndvi_a_p05', 'ncorte', 'areaesti','linhas_falha_km', 'chuva_dia_p04', 'chuva_dia_p12',\n",
    "       'bal_hidrico_p12', 'bal_hidrico_p04', 'espacamento_m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chamando o arquivo csv apenas com as colunas necessarias\n",
    "base = pd.read_csv('sample_train_dataset_tch_pred.csv', usecols = colunas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizando os dados(alterando os dados para uma escala comum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Objetivo:*** Alterar os valores das colunas numéricas no conjunto de dados para uma escala comum, sem distorcer as diferenças nos intervalos de valores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando biblioteca para normalizar os dados\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizando os dados para as variaveis indepedentes\n",
    "x_scal = MinMaxScaler()\n",
    "base[['ndvi_a_p05', 'ncorte', 'areaesti','linhas_falha_km', 'chuva_dia_p04', 'chuva_dia_p12',\n",
    "       'bal_hidrico_p12', 'bal_hidrico_p04', 'espacamento_m']] = x_scal.fit_transform(base[['ndvi_a_p05', 'ncorte', 'areaesti','linhas_falha_km', 'chuva_dia_p04', 'chuva_dia_p12',\n",
    "       'bal_hidrico_p12', 'bal_hidrico_p04', 'espacamento_m']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizando as variaveis para y\n",
    "y_scal = MinMaxScaler()\n",
    "base[['tch']] = y_scal.fit_transform(base[['tch']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y recebendo a variavel depedente tch\n",
    "y = base['tch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x recebendo a lista com as variaveis indepedentes de x\n",
    "x = base.drop('tch', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividindo os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#featues colunas\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "colunas_x = [tf.feature_column.numeric_column(key = c) for c in colunas_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividindo a base de dados em teste e train para o modelo\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_treinamento, x_teste, y_treinamento, y_teste = train_test_split(x,y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definido função para treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function train\n",
    "function_treinamento = tf.estimator.inputs.pandas_input_fn(x = x_treinamento, y = y_treinamento, batch_size = 8, num_epochs = None, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo função para teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function test\n",
    "function_teste = tf.estimator.inputs.pandas_input_fn(x = x_teste, y = y_teste, batch_size = 8, num_epochs=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando a função de regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando modelo de regressao\n",
    "regressor = tf.estimator.LinearRegressor(feature_columns=colunas_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazendo treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training model, objetivo loss fuction diminua\n",
    "regressor.train(input_fn=function_treinamento, steps = 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metricas do treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metricas de treinamento\n",
    "metricas_treinamento = regressor.evaluate(input_fn=function_treinamento,steps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metricas Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testando modelo com as variaveis x_teste e y_teste\n",
    "metricas_teste = regressor.evaluate(input_fn=function_teste,steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresentando metricas do treinamento\n",
    "metricas_treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresentando metricas do teste\n",
    "metricas_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função Previsão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a função para fazer a previsao\n",
    "funcao_previsao = tf.estimator.inputs.pandas_input_fn(x = x_teste,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executando a previsao\n",
    "previsao = regressor.predict(input_fn=funcao_previsao)\n",
    "# Visualizando os resultados previstos\n",
    "#list(previsao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizando os pesos dos estimadores de parâmetros com tensorflow\n",
    "* Os estimadores de parâmetros(pesos) são utilizados para estimar a reta da regressão multípla, através deste parâmetros conseguimos estimar a reta para então utiliza-los para prever(variaveis depedentes) novos pontos(variaveis indepedentes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para retornar os valores dos pesos\n",
    "def list__value_param():\n",
    "    name_param = regressor.get_variable_names()\n",
    "    value_param = []\n",
    "    name_value_param = []\n",
    "    for val in name_param:\n",
    "        value_param.append(regressor.get_variable_value(val))\n",
    "        \n",
    "    value_param = np.asarray(value_param[1:]).reshape(-1,1)# Convertendo para numpy\n",
    "    name_param = np.asarray(name_param[1:]).reshape(-1,1)\n",
    "\n",
    "    name_value_param = zip(name_param,value_param)\n",
    "    name_value_param = np.asarray(name_value_param).reshape(-1,2)\n",
    "    name_value_param = dict(name_value_param)\n",
    "    return name_value_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chamando função para retornar os pesos\n",
    "name_param = list__value_param()\n",
    "\n",
    "#Apresentando as dicts\n",
    "cont  = 0\n",
    "for key , value in name_param.items():\n",
    "    print(\" B{} : {}\".format(cont,value))\n",
    "    cont = cont +1\n",
    "    #print(key, \" :: \", value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserindo os predicts em uma lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colocando as predicts numa lista\n",
    "val_predict =[]\n",
    "for p in regressor.predict(input_fn=funcao_previsao):\n",
    "    val_predict.append(p['predictions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os dados para visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voltando para os dados sem escalonamento, utilizando função inversa \n",
    "# Inversa transformação para predict\n",
    "pr = y_scal.inverse_transform(val_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo do formato Series para um array\n",
    "# Onde (-1,1), -1 significa para as linhas permanecerem e 1 para uma coluna\n",
    "y_tes = y_teste.values.reshape(-1,1)\n",
    "\n",
    "# Inversa transformação para predict\n",
    "y_t = y_scal.inverse_transform(y_tes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando os dados para predict\n",
    "len(val_predict)#list\n",
    "\n",
    "import numpy as np \n",
    "# Convertendo do formato Series para um array\n",
    "# Onde (-1,1), -1 significa para as linhas permanecerem e 1 para uma coluna\n",
    "val_predict = np.array(val_predict).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizando o erro por mae(mean absolute error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando mean absolute error para calcular o erro entre y_teste e o predict\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_t,pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizando mae\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotando o gráfico de y_teste e predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotando gráfico de y_teste e predict\n",
    "plt.plot(y_t, 'o')\n",
    "plt.plot(pr, '*', color = 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
